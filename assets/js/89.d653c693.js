(window.webpackJsonp=window.webpackJsonp||[]).push([[89],{362:function(t,s,a){"use strict";a.r(s);var n=a(14),e=Object(n.a)({},(function(){var t=this,s=t._self._c;return s("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[s("h1",{attrs:{id:"react中diff算法的理解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#react中diff算法的理解"}},[t._v("#")]),t._v(" React中diff算法的理解")]),t._v(" "),s("p",[s("code",[t._v("diff")]),t._v("算法用来计算出"),s("code",[t._v("Virtual DOM")]),t._v("中改变的部分，然后针对该部分进行"),s("code",[t._v("DOM")]),t._v("操作，而不用重新渲染整个页面，渲染整个"),s("code",[t._v("DOM")]),t._v("结构的过程中开销是很大的，需要浏览器对"),s("code",[t._v("DOM")]),t._v("结构进行重绘与回流，而"),s("code",[t._v("diff")]),t._v("算法能够使得操作过程中只更新修改的那部分"),s("code",[t._v("DOM")]),t._v("结构而不更新整个"),s("code",[t._v("DOM")]),t._v("，这样能够最小化操作"),s("code",[t._v("DOM")]),t._v("结构，能够最大程度上减少浏览器重绘与回流的规模。")]),t._v(" "),s("h2",{attrs:{id:"虚拟dom"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#虚拟dom"}},[t._v("#")]),t._v(" 虚拟DOM")]),t._v(" "),s("p",[s("code",[t._v("diff")]),t._v("算法的基础是"),s("code",[t._v("Virtual DOM")]),t._v("，"),s("code",[t._v("Virtual DOM")]),t._v("是一棵以"),s("code",[t._v("JavaScript")]),t._v("对象作为基础的树，在"),s("code",[t._v("React")]),t._v("中通常是通过"),s("code",[t._v("JSX")]),t._v("编译而成的，每一个节点称为"),s("code",[t._v("VNode")]),t._v("，用对象属性来描述节点，实际上它是一层对真实"),s("code",[t._v("DOM")]),t._v("的抽象，最终可以通过渲染操作使这棵树映射到真实环境上，简单来说"),s("code",[t._v("Virtual DOM")]),t._v("就是一个"),s("code",[t._v("Js")]),t._v("对象，用以描述整个文档。"),s("br"),t._v("\n在浏览器中构建页面时需要使用"),s("code",[t._v("DOM")]),t._v("节点描述整个文档。")]),t._v(" "),s("div",{staticClass:"language-html extra-class"},[s("pre",{pre:!0,attrs:{class:"language-html"}},[s("code",[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("div")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("class")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("root"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),t._v(" "),s("span",{pre:!0,attrs:{class:"token attr-name"}},[t._v("name")]),s("span",{pre:!0,attrs:{class:"token attr-value"}},[s("span",{pre:!0,attrs:{class:"token punctuation attr-equals"}},[t._v("=")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')]),t._v("root"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v('"')])]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("p")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("1"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("p")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("<")]),t._v("div")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("11"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("div")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token tag"}},[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("</")]),t._v("div")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(">")])]),t._v("\n")])])]),s("p",[t._v("如果使用"),s("code",[t._v("Js")]),t._v("对象去描述上述的节点以及文档，那么便类似于下面的样子，当然这不是"),s("code",[t._v("React")]),t._v("中用以描述节点的对象，"),s("code",[t._v("React")]),t._v("中创建一个"),s("code",[t._v("React")]),t._v("元素的相关源码在"),s("code",[t._v("react/src/ReactElement.js")]),t._v("中，文中的"),s("code",[t._v("React")]),t._v("版本是"),s("code",[t._v("16.10.2")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"div"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("props")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("className")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("name")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"root"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("children")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"p"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("props")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("children")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"text"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("props")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"1"')]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n                    \n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("    \n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"div"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("props")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("children")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("type")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"text"')]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("props")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n                        "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("text")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v('"11"')]),t._v("\n                    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n                "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("实际上在"),s("code",[t._v("React16")]),t._v("中启用了全新的架构"),s("code",[t._v("Fiber")]),t._v("，"),s("code",[t._v("Fiber")]),t._v("核心是实现了一个基于优先级和"),s("code",[t._v("requestIdleCallback")]),t._v("的循环任务调度算法，相关问题不在文章中讨论，相关的问题大致在于虚拟"),s("code",[t._v("DOM")]),t._v("由树结构转变成链表结构，原来的"),s("code",[t._v("VDOM")]),t._v("是一颗由上至下的树，通过深度优先遍历，层层递归直下，然而这个深度优先遍历最大的毛病在于不可中断，因此我们在"),s("code",[t._v("diff + patch")]),t._v("又或者是"),s("code",[t._v("Mount")]),t._v("巨大节点的时候，会造成较大的卡顿，"),s("code",[t._v("React16")]),t._v("的"),s("code",[t._v("VDOM")]),t._v("不再是一颗由上至下那么简单的树，而是链表形式的虚拟"),s("code",[t._v("DOM")]),t._v("，链表的每一个节点是"),s("code",[t._v("Fiber")]),t._v("，而不是在"),s("code",[t._v("16")]),t._v("之前的虚拟"),s("code",[t._v("DOM")]),t._v("节点，每个"),s("code",[t._v("Fiber")]),t._v("节点记录着诸多信息，以便走到某个节点的时候中断，"),s("code",[t._v("Fiber")]),t._v("的思路是把渲染/更新过程(递归"),s("code",[t._v("diff")]),t._v(")拆分成一系列小任务，每次检查树上的一小部分，做完看是否还有时间继续下一个任务，有的话继续，没有的话把自己挂起，主线程不忙的时候再继续。"),s("code",[t._v("Fiber")]),t._v("在"),s("code",[t._v("diff")]),t._v("阶段，做了如下的操作，实际相当于在"),s("code",[t._v("15")]),t._v("的"),s("code",[t._v("diff")]),t._v("算法阶段，做了优先级的任务调度控制。")]),t._v(" "),s("ul",[s("li",[t._v("把可中断的工作拆分成小任务。")]),t._v(" "),s("li",[t._v("对正在做的工作调整优先次序、重做、复用上次(未完成)工作。")]),t._v(" "),s("li",[s("code",[t._v("diff")]),t._v("阶段任务调度优先级控制。")])]),t._v(" "),s("h3",{attrs:{id:"操作虚拟dom与操作原生dom的比较"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#操作虚拟dom与操作原生dom的比较"}},[t._v("#")]),t._v(" 操作虚拟DOM与操作原生DOM的比较")]),t._v(" "),s("p",[t._v("在这里直接引用了尤大的话("),s("code",[t._v("2016-02-08")]),t._v("年的回答，此时"),s("code",[t._v("Vue2.0")]),t._v("还未发布，"),s("code",[t._v("Vue2.0")]),t._v("于"),s("code",[t._v("2016-10-01")]),t._v("左右发布，"),s("code",[t._v("Vue2.0")]),t._v("才加入虚拟"),s("code",[t._v("DOM")]),t._v(")，相关链接为"),s("code",[t._v("https://www.zhihu.com/question/31809713")]),t._v("，建议结合链接中的问题阅读，也可以看看问题中比较的示例，另外下面的回答也都非常的精髓。")]),t._v(" "),s("h4",{attrs:{id:"原生-dom-操作-vs-通过框架封装操作"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#原生-dom-操作-vs-通过框架封装操作"}},[t._v("#")]),t._v(" 原生 DOM 操作 vs 通过框架封装操作")]),t._v(" "),s("p",[t._v("这是一个性能"),s("code",[t._v("vs")]),t._v("可维护性的取舍，框架的意义在于为你掩盖底层的"),s("code",[t._v("DOM")]),t._v("操作，让你用更声明式的方式来描述你的目的，从而让你的代码更容易维护，没有任何框架可以比纯手动的优化"),s("code",[t._v("DOM")]),t._v("操作更快，因为框架的"),s("code",[t._v("DOM")]),t._v("操作层需要应对任何上层"),s("code",[t._v("API")]),t._v("可能产生的操作，它的实现必须是普适的，针对任何一个"),s("code",[t._v("benchmark")]),t._v("，我都可以写出比任何框架更快的手动优化，但是那有什么意义呢?在构建一个实际应用的时候，你难道为每一个地方都去做手动优化吗?出于可维护性的考虑，这显然不可能，框架给你的保证是，你在不需要手动优化的情况下，我依然可以给你提供过得去的性能。")]),t._v(" "),s("h4",{attrs:{id:"对-react-的-virtual-dom-的误解"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#对-react-的-virtual-dom-的误解"}},[t._v("#")]),t._v(" 对 React 的 Virtual DOM 的误解")]),t._v(" "),s("p",[s("code",[t._v("React")]),t._v("从来没有说过"),s("code",[t._v("React")]),t._v("比原生操作"),s("code",[t._v("DOM")]),t._v("快，"),s("code",[t._v("React")]),t._v("的基本思维模式是每次有变动就整个重新渲染整个应用，如果没有"),s("code",[t._v("Virtual DOM")]),t._v("，简单来想就是直接重置"),s("code",[t._v("innerHTML")]),t._v("，很多人都没有意识到，在一个大型列表所有数据都变了的情况下，重置"),s("code",[t._v("innerHTML")]),t._v("其实是一个还算合理的操作，真正的问题是在全部重新渲染的思维模式下，即使只有一行数据变了，它也需要重置整个"),s("code",[t._v("innerHTML")]),t._v("，这时候显然就有大量的浪费。"),s("br"),t._v("\n我们可以比较一下"),s("code",[t._v("innerHTML vs Virtual DOM")]),t._v("的重绘性能消耗：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("innerHTML")]),t._v(": "),s("code",[t._v("render html string O(template size)")]),t._v(" + 重新创建所有"),s("code",[t._v("DOM")]),t._v("元素"),s("code",[t._v("O(DOM size)")])]),t._v(" "),s("li",[s("code",[t._v("Virtual DOM")]),t._v(": "),s("code",[t._v("render Virtual DOM + diff O(template size)")]),t._v(" + 必要的"),s("code",[t._v("DOM")]),t._v("更新"),s("code",[t._v("O(DOM change)")]),t._v("。")])]),t._v(" "),s("p",[s("code",[t._v("Virtual DOM render + diff")]),t._v("显然比渲染"),s("code",[t._v("html")]),t._v("字符串要慢，但是!它依然是纯"),s("code",[t._v("js")]),t._v("层面的计算，比起后面的"),s("code",[t._v("DOM")]),t._v("操作来说，依然便宜了太多，可以看到，"),s("code",[t._v("innerHTML")]),t._v("的总计算量不管是"),s("code",[t._v("js")]),t._v("计算还是"),s("code",[t._v("DOM")]),t._v("操作都是和整个界面的大小相关，但"),s("code",[t._v("Virtual DOM")]),t._v("的计算量里面，只有"),s("code",[t._v("js")]),t._v("计算和界面大小相关，"),s("code",[t._v("DOM")]),t._v("操作是和数据的变动量相关的，前面说了，和"),s("code",[t._v("DOM")]),t._v("操作比起来，"),s("code",[t._v("js")]),t._v("计算是极其便宜的，这才是为什么要有"),s("code",[t._v("Virtual DOM:")]),t._v("它保证了 "),s("code",[t._v("1)")]),t._v("不管你的数据变化多少，每次重绘的性能都可以接受; "),s("code",[t._v("2)")]),t._v("你依然可以用类似"),s("code",[t._v("innerHTML")]),t._v("的思路去写你的应用。")]),t._v(" "),s("h4",{attrs:{id:"mvvm-vs-virtual-dom"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#mvvm-vs-virtual-dom"}},[t._v("#")]),t._v(" MVVM vs Virtual DOM")]),t._v(" "),s("p",[t._v("相比起"),s("code",[t._v("React")]),t._v("，其他"),s("code",[t._v("MVVM")]),t._v("系框架比如"),s("code",[t._v("Angular, Knockout")]),t._v("以及"),s("code",[t._v("Vue")]),t._v("、"),s("code",[t._v("Avalon")]),t._v("采用的都是数据绑定"),s("code",[t._v(":")]),t._v("通过"),s("code",[t._v("Directive/Binding")]),t._v("对象，观察数据变化并保留对实际"),s("code",[t._v("DOM")]),t._v("元素的引用，当有数据变化时进行对应的操作，"),s("code",[t._v("MVVM")]),t._v("的变化检查是数据层面的，而"),s("code",[t._v("React")]),t._v("的检查是"),s("code",[t._v("DOM")]),t._v("结构层面的，"),s("code",[t._v("MVVM")]),t._v("的性能也根据变动检测的实现原理有所不同: "),s("code",[t._v("Angular")]),t._v("的脏检查使得任何变动都有固定的"),s("code",[t._v("O(watcher count)")]),t._v("的代价; "),s("code",[t._v("Knockout/Vue/Avalon")]),t._v("都采用了依赖收集，在"),s("code",[t._v("js")]),t._v("和"),s("code",[t._v("DOM")]),t._v("层面都是"),s("code",[t._v("O(change)")]),t._v(":")]),t._v(" "),s("ul",[s("li",[t._v("脏检查："),s("code",[t._v("scope digest O(watcher count)")]),t._v(" + 必要"),s("code",[t._v("DOM")]),t._v("更新"),s("code",[t._v("O(DOM change)")]),t._v("。")]),t._v(" "),s("li",[t._v("依赖收集：重新收集依赖"),s("code",[t._v("O(data change)")]),t._v(" + 必要"),s("code",[t._v("DOM")]),t._v("更新 "),s("code",[t._v("O(DOM change)")]),t._v("。")])]),t._v(" "),s("p",[t._v("可以看到，"),s("code",[t._v("Angular")]),t._v("最不效率的地方在于任何小变动都有的和"),s("code",[t._v("watcher")]),t._v("数量相关的性能代价，但是!当所有数据都变了的时候，"),s("code",[t._v("Angular")]),t._v("其实并不吃亏，依赖收集在初始化和数据变化的时候都需要重新收集依赖，这个代价在小量更新的时候几乎可以忽略，但在数据量庞大的时候也会产生一定的消耗。"),s("br"),t._v(" "),s("code",[t._v("MVVM")]),t._v("渲染列表的时候，由于每一行都有自己的数据作用域，所以通常都是每一行有一个对应的"),s("code",[t._v("ViewModel")]),t._v("实例，或者是一个稍微轻量一些的利用原型继承的"),s("code",[t._v("scope")]),t._v("对象，但也有一定的代价，所以"),s("code",[t._v("MVVM")]),t._v("列表渲染的初始化几乎一定比"),s("code",[t._v("React")]),t._v("慢，因为创建"),s("code",[t._v("ViewModel / scope")]),t._v("实例比起"),s("code",[t._v("Virtual DOM")]),t._v("来说要昂贵很多，这里所有"),s("code",[t._v("MVVM")]),t._v("实现的一个共同问题就是在列表渲染的数据源变动时，尤其是当数据是全新的对象时，如何有效地复用已经创建的"),s("code",[t._v("ViewModel")]),t._v("实例和"),s("code",[t._v("DOM")]),t._v("元素，假如没有任何复用方面的优化，由于数据是全新的，"),s("code",[t._v("MVVM")]),t._v("实际上需要销毁之前的所有实例，重新创建所有实例，最后再进行一次渲染!这就是为什么题目里链接的"),s("code",[t._v("angular/knockout")]),t._v("实现都相对比较慢，相比之下，"),s("code",[t._v("React")]),t._v("的变动检查由于是"),s("code",[t._v("DOM")]),t._v("结构层面的，即使是全新的数据，只要最后渲染结果没变，那么就不需要做无用功。"),s("br"),t._v("\n顺道说一句，"),s("code",[t._v("React")]),t._v("渲染列表的时候也需要提供"),s("code",[t._v("key")]),t._v("这个特殊"),s("code",[t._v("prop")]),t._v("，本质上和"),s("code",[t._v("track-by")]),t._v("是一回事。")]),t._v(" "),s("h4",{attrs:{id:"性能比较也要看场合"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#性能比较也要看场合"}},[t._v("#")]),t._v(" 性能比较也要看场合")]),t._v(" "),s("p",[t._v("在比较性能的时候，要分清楚初始渲染、小量数据更新、大量数据更新这些不同的场合，"),s("code",[t._v("Virtual DOM")]),t._v("、脏检查"),s("code",[t._v("MVVM")]),t._v("、数据收集"),s("code",[t._v("MVVM")]),t._v("在不同场合各有不同的表现和不同的优化需求，"),s("code",[t._v("Virtual DOM")]),t._v("为了提升小量数据更新时的性能，也需要针对性的优化，比如"),s("code",[t._v("shouldComponentUpdate")]),t._v("或是"),s("code",[t._v("immutable data")]),t._v("。")]),t._v(" "),s("ul",[s("li",[t._v("初始渲染："),s("code",[t._v("Virtual DOM")]),t._v(" > 脏检查 >= 依赖收集。")]),t._v(" "),s("li",[t._v("小量数据更新：依赖收集 >> "),s("code",[t._v("Virtual DOM")]),t._v(" + 优化 > 脏检查(无法优化) > "),s("code",[t._v("Virtual DOM")]),t._v("无优化。")]),t._v(" "),s("li",[t._v("大量数据更新：脏检查 + 优化 >= 依赖收集 + 优化 > "),s("code",[t._v("Virtual DOM")]),t._v("(无法/无需优化) >> "),s("code",[t._v("MVVM")]),t._v("无优化。")])]),t._v(" "),s("p",[t._v("不要天真地以为"),s("code",[t._v("Virtual DOM")]),t._v("就是快，"),s("code",[t._v("diff")]),t._v("不是免费的，"),s("code",[t._v("batching")]),t._v("么"),s("code",[t._v("MVVM")]),t._v("也能做，而且最终"),s("code",[t._v("patch")]),t._v("的时候还不是要用原生"),s("code",[t._v("API")]),t._v("，在我看来"),s("code",[t._v("Virtual DOM")]),t._v("真正的价值从来都不是性能，而是它 "),s("code",[t._v("1)")]),t._v("为函数式的"),s("code",[t._v("UI")]),t._v("编程方式打开了大门; "),s("code",[t._v("2)")]),t._v("可以渲染到"),s("code",[t._v("DOM")]),t._v("以外的"),s("code",[t._v("backend")]),t._v("，比如"),s("code",[t._v("ReactNative")]),t._v("。")]),t._v(" "),s("h4",{attrs:{id:"总结"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#总结"}},[t._v("#")]),t._v(" 总结")]),t._v(" "),s("p",[t._v("以上这些比较，更多的是对于框架开发研究者提供一些参考，主流的框架"),s("code",[t._v("+")]),t._v("合理的优化，足以应对绝大部分应用的性能需求，如果是对性能有极致需求的特殊情况，其实应该牺牲一些可维护性采取手动优化"),s("code",[t._v(":")]),t._v("比如"),s("code",[t._v("Atom")]),t._v("编辑器在文件渲染的实现上放弃了"),s("code",[t._v("React")]),t._v("而采用了自己实现的"),s("code",[t._v("tile-based rendering")]),t._v("; 又比如在移动端需要"),s("code",[t._v("DOM-pooling")]),t._v("的虚拟滚动，不需要考虑顺序变化，可以绕过框架的内置实现自己搞一个。")]),t._v(" "),s("h2",{attrs:{id:"diff算法"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#diff算法"}},[t._v("#")]),t._v(" diff算法")]),t._v(" "),s("p",[s("code",[t._v("React")]),t._v("在内存中维护一颗虚拟"),s("code",[t._v("DOM")]),t._v("树，当数据发生改变时("),s("code",[t._v("state & props")]),t._v(")，会自动的更新虚拟"),s("code",[t._v("DOM")]),t._v("，获得一个新的虚拟"),s("code",[t._v("DOM")]),t._v("树，然后通过"),s("code",[t._v("Diff")]),t._v("算法，比较新旧虚拟"),s("code",[t._v("DOM")]),t._v("树，找出最小的有变化的部分，将这个变化的部分"),s("code",[t._v("Patch")]),t._v("加入队列，最终批量的更新这些"),s("code",[t._v("Patch")]),t._v("到实际的"),s("code",[t._v("DOM")]),t._v("中。")]),t._v(" "),s("h3",{attrs:{id:"时间复杂度"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#时间复杂度"}},[t._v("#")]),t._v(" 时间复杂度")]),t._v(" "),s("p",[t._v("首先进行一次完整的"),s("code",[t._v("diff")]),t._v("需要"),s("code",[t._v("O(n^3)")]),t._v("的时间复杂度，这是一个最小编辑距离的问题，在比较字符串的最小编辑距离时使用动态规划的方案需要的时间复杂度是"),s("code",[t._v("O(mn)")]),t._v("，但是对于"),s("code",[t._v("DOM")]),t._v("来说是一个树形结构，而树形结构的最小编辑距离问题的时间复杂度在"),s("code",[t._v("30")]),t._v("多年的演进中从"),s("code",[t._v("O(m^3n^3)")]),t._v("演进到了"),s("code",[t._v("O(n^3)")]),t._v("，关于这个问题如果有兴趣的话可以研究一下论文"),s("code",[t._v("https://grfia.dlsi.ua.es/ml/algorithms/references/editsurvey_bille.pdf")]),t._v("。"),s("br"),t._v("\n对于原本想要提高效率而引入的"),s("code",[t._v("diff")]),t._v("算法使用"),s("code",[t._v("O(n^3)")]),t._v("的时间复杂度显然是不太合适的，如果有"),s("code",[t._v("1000")]),t._v("个节点元素将需要进行十亿次比较，这是一个昂贵的算法，所以必须有一些妥协来加快速度，对比较通过一些策略进行简化，将时间复杂度缩小到"),s("code",[t._v("O(n)")]),t._v("，虽然并不是最小编辑距离，但是作为编辑距离与时间性能的综合考量是一个比较好的解决方案，是一种比较好的折中方案。")]),t._v(" "),s("h3",{attrs:{id:"diff策略"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#diff策略"}},[t._v("#")]),t._v(" diff策略")]),t._v(" "),s("p",[t._v("上边提到的"),s("code",[t._v("O(n)")]),t._v("时间复杂度是通过一定策略进行的，"),s("code",[t._v("React")]),t._v("文档中提到了两个假设：")]),t._v(" "),s("ul",[s("li",[t._v("两个不同类型的元素将产生不同的树。")]),t._v(" "),s("li",[t._v("通过渲染器附带"),s("code",[t._v("key")]),t._v("属性，开发者可以示意哪些子元素可能是稳定的。")])]),t._v(" "),s("p",[t._v("通俗点说就是：")]),t._v(" "),s("ul",[s("li",[t._v("只进行统一层级的比较，如果跨层级的移动则视为创建和删除操作。")]),t._v(" "),s("li",[t._v("如果是不同类型的元素，则认为是创建了新的元素，而不会递归比较他们的孩子。")]),t._v(" "),s("li",[t._v("如果是列表元素等比较相似的内容，可以通过"),s("code",[t._v("key")]),t._v("来唯一确定是移动还是创建或删除操作。")])]),t._v(" "),s("p",[t._v("比较后会出现几种情况，然后进行相应的操作：")]),t._v(" "),s("ul",[s("li",[t._v("此节点被添加或移除"),s("code",[t._v("->")]),t._v("添加或移除新的节点。")]),t._v(" "),s("li",[t._v("属性被改变"),s("code",[t._v("->")]),t._v("旧属性改为新属性。")]),t._v(" "),s("li",[t._v("文本内容被改变"),s("code",[t._v("->")]),t._v("旧内容改为新内容。")]),t._v(" "),s("li",[t._v("节点"),s("code",[t._v("tag")]),t._v("或"),s("code",[t._v("key")]),t._v("是否改变"),s("code",[t._v("->")]),t._v("改变则移除后创建新元素。")])]),t._v(" "),s("h3",{attrs:{id:"分析"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#分析"}},[t._v("#")]),t._v(" 分析")]),t._v(" "),s("p",[t._v("在分析时会简单引用一下在"),s("code",[t._v("React")]),t._v("的源码，起辅助作用的代码，实际源码是很复杂的，引用的是一部分片段帮助理解，本文的源码"),s("code",[t._v("TAG")]),t._v("为"),s("code",[t._v("16.10.2")]),t._v("。"),s("br"),t._v("\n关于"),s("code",[t._v("if (__DEV__){...}")]),t._v("相关代码实际上是为更好的开发者体验而编写的，"),s("code",[t._v("React")]),t._v("中的友好的报错，"),s("code",[t._v("render")]),t._v("性能测试等等代码都是写在"),s("code",[t._v("if (__DEV__)")]),t._v("中的，在"),s("code",[t._v("production build")]),t._v("的时候，这些代码不会被打包，因此我们可以毫无顾虑的提供专为开发者服务的代码，"),s("code",[t._v("React")]),t._v("的最佳实践之一就是在开发时使用"),s("code",[t._v("development build")]),t._v("，在生产环境使用"),s("code",[t._v("production build")]),t._v("，所以我们实际上可以先跳过这部分代码，专注于理解较为核心的部分。"),s("br"),t._v("\n我们分析"),s("code",[t._v("diff")]),t._v("算法是从"),s("code",[t._v("reconcileChildren")]),t._v("开始的，之前从"),s("code",[t._v("setState -> enqueueSetState(UpdateQueue) -> scheduleUpdate -> performWork -> workLoop -> beginWork -> finishClassComponent -> reconcileChildren")]),t._v("相关的部分就不过多介绍了，需要注意的是"),s("code",[t._v("beginWork")]),t._v("会将一个一个的"),s("code",[t._v("Fiber")]),t._v("来进行"),s("code",[t._v("diff")]),t._v("，期间是可中断的，因为每次执行下一个"),s("code",[t._v("Fiber")]),t._v("的比对时，都会先判断这一帧剩余的时间是否充足，链表的每一个节点是"),s("code",[t._v("Fiber")]),t._v("，而不是在"),s("code",[t._v("16")]),t._v("之前的虚拟"),s("code",[t._v("DOM")]),t._v("节点，每一个"),s("code",[t._v("Fiber")]),t._v("都有"),s("code",[t._v("React16")]),t._v("的"),s("code",[t._v("diff")]),t._v("策略采用从链表头部开始比较的算法，是链式的深度优先遍历，即已经从树形结构变成了链表结构，实际相当于在"),s("code",[t._v("15")]),t._v("的"),s("code",[t._v("diff")]),t._v("算法阶段，做了优先级的任务调度控制。此外，每个"),s("code",[t._v("Fiber")]),t._v("都会有一个"),s("code",[t._v("child")]),t._v("、"),s("code",[t._v("sibling")]),t._v("、"),s("code",[t._v("return")]),t._v("三大属性作为链接树前后的指针；"),s("code",[t._v("child")]),t._v("作为模拟树结构的结构指针；"),s("code",[t._v("effectTag")]),t._v("一个很有意思的标记，用于记录"),s("code",[t._v("effect")]),t._v("的类型，"),s("code",[t._v("effect")]),t._v("指的就是对"),s("code",[t._v("DOM")]),t._v("操作的方式，比如修改，删除等操作，用于到后面进行"),s("code",[t._v("commit")]),t._v("(类似数据库)；"),s("code",[t._v("firstEffect")]),t._v("、"),s("code",[t._v("lastEffect")]),t._v("等玩意是用来保存中断前后"),s("code",[t._v("effect")]),t._v("的状态，用户中断后恢复之前的操作以及"),s("code",[t._v("tag")]),t._v("用于标记。"),s("br"),t._v(" "),s("code",[t._v("reconcileChildren")]),t._v("实现的就是江湖上广为流传的"),s("code",[t._v("Virtul DOM diff")]),t._v("，其实际上只是一个入口函数，如果首次渲染，"),s("code",[t._v("current")]),t._v("空"),s("code",[t._v("null")]),t._v("，就通过"),s("code",[t._v("mountChildFibers")]),t._v("创建子节点的"),s("code",[t._v("Fiber")]),t._v("实例，如果不是首次渲染，就调用"),s("code",[t._v("reconcileChildFibers")]),t._v("去做"),s("code",[t._v("diff")]),t._v("，然后得出"),s("code",[t._v("effect list")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 1246")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("export")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token parameter"}},[s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("current")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("workInProgress")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("nextChildren")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" any"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("renderExpirationTime")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" ExpirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")])]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("current "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 首次渲染 创建子节点的`Fiber`实例")]),t._v("\n    workInProgress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("child "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mountChildFibers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      workInProgress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      nextChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      renderExpirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 否则调用`reconcileChildFibers`去做`diff`")]),t._v("\n    workInProgress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("child "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileChildFibers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      workInProgress"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      current"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      nextChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      renderExpirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("对比一下"),s("code",[t._v("mountChildFibers")]),t._v("和"),s("code",[t._v("reconcileChildFibers")]),t._v("有什么区别，可以看出他们都是通过"),s("code",[t._v("ChildReconciler")]),t._v("工厂函数来的，只是传递的参数不同而已，这个参数叫"),s("code",[t._v("shouldTrackSideEffects")]),t._v("，他的作用是判断是否要增加一些"),s("code",[t._v("effectTag")]),t._v("，主要是用来优化初次渲染的，因为初次渲染没有更新操作。"),s("code",[t._v("ChildReconciler")]),t._v("是一个超级长的工厂(包装)函数，内部有很多"),s("code",[t._v("helper")]),t._v("函数，最终返回的函数叫"),s("code",[t._v("reconcileChildFibers")]),t._v("，这个函数实现了对子"),s("code",[t._v("fiber")]),t._v("节点的"),s("code",[t._v("reconciliation")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 1370")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("export")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" reconcileChildFibers "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("ChildReconciler")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("true")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("export")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" mountChildFibers "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("ChildReconciler")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("ChildReconciler")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token parameter"}},[t._v("shouldTrackSideEffects")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" \n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("useFiber")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("placeChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("placeSingleChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateTextNode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateElement")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updatePortal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateFragment")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateSlot")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateFromMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("warnOnInvalidKey")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileChildrenArray")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileChildrenIterator")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileSingleTextNode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileSingleElement")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileSinglePortal")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileChildFibers")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" reconcileChildFibers"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("code",[t._v("reconcileChildFibers")]),t._v("就是"),s("code",[t._v("diff")]),t._v("部分的主体代码，相关操作都在"),s("code",[t._v("ChildReconciler")]),t._v("函数中，在这个函数中相关参数，"),s("code",[t._v("returnFiber")]),t._v("是即将"),s("code",[t._v("diff")]),t._v("的这层的父节点，"),s("code",[t._v("currentFirstChild")]),t._v("是当前层的第一个"),s("code",[t._v("Fiber")]),t._v("节点，"),s("code",[t._v("newChild")]),t._v("是即将更新的"),s("code",[t._v("vdom")]),t._v("节点(可能是"),s("code",[t._v("TextNode")]),t._v("、可能是"),s("code",[t._v("ReactElement")]),t._v("，可能是数组)，不是"),s("code",[t._v("Fiber")]),t._v("节点。"),s("code",[t._v("expirationTime")]),t._v("是过期时间，这个参数是跟调度有关系的，跟"),s("code",[t._v("diff")]),t._v("没有太大关系，另外需要注意的是，"),s("code",[t._v("reconcileChildFibers")]),t._v(" 是"),s("code",[t._v("reconcile(diff)")]),t._v("的一层结构。")]),t._v(" "),s("p",[t._v("首先看"),s("code",[t._v("TextNode")]),t._v("的"),s("code",[t._v("diff")]),t._v("，他是最简单的，对于"),s("code",[t._v("diff TextNode")]),t._v("会有两种情况：")]),t._v(" "),s("ul",[s("li",[s("code",[t._v("currentFirstNode")]),t._v("是"),s("code",[t._v("TextNode")]),t._v("。")]),t._v(" "),s("li",[s("code",[t._v("currentFirstNode")]),t._v("不是"),s("code",[t._v("TextNode")]),t._v("。")])]),t._v(" "),s("p",[t._v("分两种情况原因就是为了复用节点，第一种情况，"),s("code",[t._v("xxx")]),t._v("是一个"),s("code",[t._v("TextNode")]),t._v("，那么就代表这这个节点可以复用，有复用的节点，对性能优化很有帮助，既然新的"),s("code",[t._v("child")]),t._v("只有一个"),s("code",[t._v("TextNode")]),t._v("，那么复用节点之后，就把剩下的"),s("code",[t._v("aaa")]),t._v("节点就可以删掉了，那么"),s("code",[t._v("div")]),t._v("的"),s("code",[t._v("child")]),t._v("就可以添加到"),s("code",[t._v("workInProgress")]),t._v("中去了。"),s("code",[t._v("useFiber")]),t._v("就是复用节点的方法，"),s("code",[t._v("deleteRemainingChildren")]),t._v("就是删除剩余节点的方法，这里是从"),s("code",[t._v("currentFirstChild.sibling")]),t._v("开始删除的。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentFirstChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tag "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" HostText"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We already have an existing node so let's just update it and delete")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the rest.")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteRemainingChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 删除兄弟")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" existing "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("useFiber")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" textContent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  existing"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("return "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" existing"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 复用")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("第二种情况，"),s("code",[t._v("xxx")]),t._v("不是一个"),s("code",[t._v("TextNode")]),t._v("，那么就代表这个节点不能复用，所以就从"),s("code",[t._v("currentFirstChild")]),t._v("开始删掉剩余的节点，其中"),s("code",[t._v("createFiberFromText")]),t._v("就是根据"),s("code",[t._v("textContent")]),t._v("来创建节点的方法，此外删除节点不会真的从链表里面把节点删除，只是打一个"),s("code",[t._v("delete")]),t._v("的"),s("code",[t._v("tag")]),t._v("，当"),s("code",[t._v("commit")]),t._v("的时候才会真正的去删除。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The existing first child is not a text node so we need to create one")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// and delete the existing ones.")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 创建新的Fiber节点，将旧的节点和旧节点的兄弟都删除 ")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteRemainingChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" created "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createFiberFromText")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n  textContent"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),s("p",[t._v("接下来是"),s("code",[t._v("React Element")]),t._v("的"),s("code",[t._v("diff")]),t._v("，此时我们处理的是该节点的父节点只有此节点一个节点的情况，与上面"),s("code",[t._v("TextNode")]),t._v("的"),s("code",[t._v("diff")]),t._v("类似，他们的思路是一致的，先找有没有可以复用的节点，如果没有就另外创建一个。此时会用到上边的两个假设用以判断节点是否可以复用，即"),s("code",[t._v("key")]),t._v("是否相同，节点类型是否相同，如果以上相同，则可以认为这个节点只是变化了内容，不需要创建新的节点，可以复用的。如果节点的类型不相同，就将节点从当前节点开始把剩余的都删除。在查找可复用节点的时候，其并不是只专注于第一个节点是否可复用，而是继续在该层中循环找到一个可以复用的节点，最顶层的"),s("code",[t._v("while")]),t._v("以及底部的"),s("code",[t._v("child = child.sibling;")]),t._v("是为了继续从子节点中找到一个"),s("code",[t._v("key")]),t._v("与"),s("code",[t._v("tag")]),t._v("相同的可复用节点，另外删除节点不会真的从链表里面把节点删除，只是打一个"),s("code",[t._v("delete")]),t._v("的"),s("code",[t._v("tag")]),t._v("，当"),s("code",[t._v("commit")]),t._v("的时候才会真正的去删除。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 1132")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" child "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// TODO: If key === null and child.key === null, then this only applies to")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// the first item in the list.")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("tag "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" Fragment\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("REACT_FRAGMENT_TYPE")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("elementType "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Keep this check inline so it only runs on the false path:")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("__DEV__\n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("isCompatibleFamilyForHotReloading")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n            "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token boolean"}},[t._v("false")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteRemainingChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 因为当前节点是只有一个节点，而老的如果是有兄弟节点是要删除的，是多余的")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" existing "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("useFiber")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("REACT_FRAGMENT_TYPE")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children\n          "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      existing"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ref "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("coerceRef")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      existing"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("return "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" existing"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteRemainingChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 从child开始delete")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  child "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" child"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 继续从子节点中找到一个可复用的节点")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("接下来就是没有找到可以复用的节点因而去创建节点了，对于"),s("code",[t._v("Fragment")]),t._v("节点和一般的"),s("code",[t._v("Element")]),t._v("节点创建的方式不同，因为"),s("code",[t._v("Fragment")]),t._v("本来就是一个无意义的节点，他真正需要创建"),s("code",[t._v("Fiber")]),t._v("的是它的"),s("code",[t._v("children")]),t._v("，而不是它自己，所以"),s("code",[t._v("createFiberFromFragment")]),t._v("传递的不是"),s("code",[t._v("element")]),t._v("，而是"),s("code",[t._v("element.props.children")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 1178")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("REACT_FRAGMENT_TYPE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" created "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createFiberFromFragment")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  created"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("return "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" created"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" created "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createFiberFromElement")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mode"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  created"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("ref "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("coerceRef")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" element"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  created"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("return "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" created"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("code",[t._v("diff Array")]),t._v("算是"),s("code",[t._v("diff")]),t._v("中最复杂的一部分了，做了很多的优化，因为"),s("code",[t._v("Fiber")]),t._v("树是单链表结构，没有子节点数组这样的数据结构，也就没有可以供两端同时比较的尾部游标，所以"),s("code",[t._v("React")]),t._v("的这个算法是一个简化的双端比较法，只从头部开始比较，在"),s("code",[t._v("Vue2.0")]),t._v("中的"),s("code",[t._v("diff")]),t._v("算法在"),s("code",[t._v("patch")]),t._v("时则是直接使用的双端比较法实现的。"),s("br"),t._v("\n首先考虑相同位置进行对比，这个是比较容易想到的一种方式，即在做"),s("code",[t._v("diff")]),t._v("的时候就可以从新旧的数组中按照索引一一对比，如果可以复用，就把这个节点从老的链表里面删除，不能复用的话再进行其他的复用策略。此时的"),s("code",[t._v("newChildren")]),t._v("数组是一个"),s("code",[t._v("VDOM")]),t._v("数组，所以在这里使用"),s("code",[t._v("updateSlot")]),t._v("包装成"),s("code",[t._v("newFiber")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 756")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("reconcileChildrenArray")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token parameter"}},[s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("returnFiber")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("currentFirstChild")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("newChildren")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Array"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("*")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("expirationTime")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" ExpirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")])]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 机翻注释")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 这个算法不能通过两端搜索来优化，因为我们在光纤上没有反向指针。我想看看我们能用这个模型走多远。如果最终不值得权衡，我们可以稍后再添加。")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 即使是双端优化，我们也希望在很少有变化的情况下进行优化，并强制进行比较，而不是去寻找地图。它想探索在前进模式下首先到达那条路径，并且只有当我们注意到我们需要很多向前看的时候才去地图。这不能处理反转以及两个结束的搜索，但这是不寻常的。此外，要使两端优化在Iterables上工作，我们需要复制整个集合。")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在第一次迭代中，我们只需在每次插入/移动时都碰到坏情况（将所有内容添加到映射中）。")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果更改此代码，还需要更新reconcileChildrenIterator()，它使用相同的算法。")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" lastPlacedIndex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" newIdx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token number"}},[t._v("0")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" nextOldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n     "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 第一个for循环，按照index一一对比，当新老节点不一致时退出循环并且记录退出时的节点及oldFiber节点")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" newIdx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" newChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" newIdx"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 位置不匹配")]),t._v("\n        nextOldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 下一个即将对比的旧节点")]),t._v("\n        oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 如果newFiber也为null(不能复用)就退出当前一一对比的for循环")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        nextOldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("//正常的情况下 为了下轮循环，拿到兄弟节点下面赋值给oldFiber")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// //如果节点可以复用(key值匹配)，就更新并且返回新节点，否则返回为null，代表节点不可以复用")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateSlot")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 判断是否可以复用节点")]),t._v("\n        returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        newChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 节点无法复用 跳出循环")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" \n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// TODO: This breaks on empty slots like null children. That's")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// unfortunate because it triggers the slow path all the time. We need")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// a better way to communicate whether this was a miss or null,")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// boolean, undefined, etc.")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nextOldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 记录不可以复用的节点并且退出对比")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("break")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 退出循环")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("shouldTrackSideEffects"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 没有复用已经存在的节点，就删除掉已经存在的节点")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("alternate "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We matched the slot, but we didn't reuse the existing fiber, so we")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// need to delete the existing child.")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 本次遍历会给新增的节点打 插入的标记")]),t._v("\n      lastPlacedIndex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("placeChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lastPlacedIndex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("previousNewFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// TODO: Move out of the loop. This only happens for the first run.")]),t._v("\n        resultingFirstChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// TODO: Defer siblings if we're not at the right index for this slot.")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// I.e. if we had null values before, then we want to defer this")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// for each null value. However, we also don't want to call updateSlot")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// with the previous one.")]),t._v("\n        previousNewFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      previousNewFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" nextOldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 重新给 oldFiber 赋值继续遍历")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("在"),s("code",[t._v("updateSlot")]),t._v("方法中定义了判断是否可以复用，对于文本节点,如果"),s("code",[t._v("key")]),t._v("不为"),s("code",[t._v("null")]),t._v("，那么就代表老节点不是"),s("code",[t._v("TextNode")]),t._v("，而新节点又是"),s("code",[t._v("TextNode")]),t._v("，所以返回"),s("code",[t._v("null")]),t._v("，不能复用，反之则可以复用，调用"),s("code",[t._v("updateTextNode")]),t._v("方法，注意"),s("code",[t._v("updateTextNode")]),t._v("里面包含了首次渲染的时候的逻辑，首次渲染的时候回插入一个"),s("code",[t._v("TextNode")]),t._v("，而不是复用。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 544")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateSlot")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token parameter"}},[s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("returnFiber")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("oldFiber")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("newChild")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" any"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("expirationTime")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" ExpirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")])]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Update the fiber if the keys match, otherwise return null.")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" newChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'string'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" newChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'number'")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 对于新的节点如果是 string 或者 number，那么都是没有 key 的，")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 所有如果老的节点有 key 的话，就不能复用，直接返回 null。")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 老的节点 key 为 null 的话，代表老的节点是文本节点，就可以复用")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateTextNode")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n        returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("''")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[s("code",[t._v("newChild")]),t._v("是"),s("code",[t._v("Object")]),t._v("的时候基本上与"),s("code",[t._v("ReactElement")]),t._v("的"),s("code",[t._v("diff")]),t._v("类似，只是没有"),s("code",[t._v("while")]),t._v("了，判断"),s("code",[t._v("key")]),t._v("和元素的类型是否相等来判断是否可以复用。首先判断是否是对象，用的是"),s("code",[t._v("typeof newChild === object")]),t._v("&&"),s("code",[t._v("newChild!== null")]),t._v("，注意要加"),s("code",[t._v("!== null")]),t._v("，因为"),s("code",[t._v("typeof null")]),t._v("也是"),s("code",[t._v("object")]),t._v("，然后通过"),s("code",[t._v("$$typeof")]),t._v("判断是"),s("code",[t._v("REACT_ELEMENT_TYPE")]),t._v("还是"),s("code",[t._v("REACT_PORTAL_TYPE")]),t._v("，分别调用不同的复用逻辑，然后由于数组也是"),s("code",[t._v("Object")]),t._v("，所以这个"),s("code",[t._v("if")]),t._v("里面也有数组的复用逻辑。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 569")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typeof")]),t._v(" newChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token string"}},[t._v("'object'")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("&&")]),t._v(" newChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("switch")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("$$"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("typeof")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("REACT_ELEMENT_TYPE")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ReactElement ")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("type "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("REACT_FRAGMENT_TYPE")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateFragment")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n            returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("props"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("children"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n            key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateElement")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n          returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n          expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("case")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token constant"}},[t._v("REACT_PORTAL_TYPE")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 调用 updatePortal")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// ...")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("isArray")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("||")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("getIteratorFn")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateFragment")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      newChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("让我们回到最初的遍历，当我们遍历完成了之后，就会有两种情况，即老节点已经遍历完毕，或者新节点已经遍历完毕，如果此时我们新节点已经遍历完毕，也就是没有要更新的了，这种情况一般就是从原来的数组里面删除了元素，那么直接把剩下的老节点删除了就行了。如果老的节点在第一次循环的时候就被复用完了，新的节点还有，很有可能就是新增了节点的情况，那么这个时候只需要根据把剩余新的节点直接创建"),s("code",[t._v("Fiber")]),t._v("就行了。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 839")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 新节点已经更新完成，删除多余的老节点")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newIdx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" newChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// We've reached the end of the new children. We can delete the rest.")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("deleteRemainingChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" resultingFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 新节点已经更新完成，删除多余的老节点")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("oldFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// If we don't have any more existing children we can choose a fast path")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// since the rest will all be insertions.")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" newIdx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" newChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" newIdx"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("createChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n      returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      newChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("continue")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    lastPlacedIndex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("placeChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lastPlacedIndex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("previousNewFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// TODO: Move out of the loop. This only happens for the first run.")]),t._v("\n      resultingFirstChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      previousNewFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    previousNewFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" resultingFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("接下来考虑移动的情况如何进行节点复用，即如果老的数组和新的数组里面都有这个元素，而且位置不相同这种情况下的复用，"),s("code",[t._v("React")]),t._v("把所有老数组元素按"),s("code",[t._v("key")]),t._v("或者是"),s("code",[t._v("index")]),t._v("放"),s("code",[t._v("Map")]),t._v("里，然后遍历新数组，根据新数组的"),s("code",[t._v("key")]),t._v("或者"),s("code",[t._v("index")]),t._v("快速找到老数组里面是否有可复用的，元素有"),s("code",[t._v("key")]),t._v("就"),s("code",[t._v("Map")]),t._v("的键就存"),s("code",[t._v("key")]),t._v("，没有"),s("code",[t._v("key")]),t._v("就存"),s("code",[t._v("index")]),t._v("。")]),t._v(" "),s("div",{staticClass:"language-javascript extra-class"},[s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 872")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Add all children to a key map for quick lookups.")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 从oldFiber开始将已经存在的节点的key或者index添加到map结构中")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" existingChildren "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapRemainingChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" oldFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Keep scanning and use the map to restore deleted items as moves.")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 剩余没有对比的新节点，到旧节点的map中通过key或者index一一对比查看是否可以复用。")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" newIdx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v(" newChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("length"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" newIdx"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("++")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 主要查看新旧节点的key或者index是否有相同的，然后再查看是否可以复用。")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" newFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("updateFromMap")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    existingChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    returnFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    newChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    expirationTime"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("shouldTrackSideEffects"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("alternate "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// The new fiber is a work in progress, but if there exists a")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// current, that means that we reused the fiber. We need to delete")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// it from the child list so that we don't add it to the deletion")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// list.")]),t._v("\n        existingChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("delete")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("  "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 在map中删除掉已经复用的节点的key或者index")]),t._v("\n          newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("?")]),t._v(" newIdx "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    lastPlacedIndex "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("placeChild")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" lastPlacedIndex"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" newIdx"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 添加newFiber到更新过的newFiber结构中。")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("previousNewFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("===")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      resultingFirstChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      previousNewFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    previousNewFiber "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" newFiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// react-reconciler/src/ReactChildFiber.js line 299")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// 将旧节点的key或者index，旧节点保存到map结构中，方便通过key或者index获取")]),t._v("\n"),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("function")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("mapRemainingChildren")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token parameter"}},[s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("returnFiber")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("currentFirstChild")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Fiber"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")])]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Map"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("string "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" number"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Fiber"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// Add the remaining children to a temporary map so that we can find them by")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// keys quickly. Implicit (null) keys get added to this set with their index")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token comment"}},[t._v("// instead.")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("const")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token literal-property property"}},[t._v("existingChildren")]),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" Map"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("<")]),t._v("string "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("|")]),t._v(" number"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Fiber"),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Map")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("let")]),t._v(" existingChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" currentFirstChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("while")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("existingChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("existingChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("null")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        existingChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("set")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("existingChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("key"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" existingChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("else")]),t._v(" "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        existingChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{pre:!0,attrs:{class:"token function"}},[t._v("set")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),t._v("existingChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("index"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" existingChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n      "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      existingChild "),s("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" existingChild"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("sibling"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("return")]),t._v(" existingChildren"),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n  "),s("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),s("p",[t._v("至此新数组遍历完毕，也就是同一层的"),s("code",[t._v("diff")]),t._v("过程完毕，我们可以把整个过程分为三个阶段:")]),t._v(" "),s("ul",[s("li",[t._v("第一遍历新数组，新老数组相同"),s("code",[t._v("index")]),t._v("进行对比，通过"),s("code",[t._v("updateSlot")]),t._v("方法找到可以复用的节点，直到找到不可以复用的节点就退出循环。")]),t._v(" "),s("li",[t._v("第一遍历完之后，删除剩余的老节点，追加剩余的新节点的过程，如果是新节点已遍历完成，就将剩余的老节点批量删除"),s("code",[t._v(";")]),t._v("如果是老节点遍历完成仍有新节点剩余，则将新节点直接插入。")]),t._v(" "),s("li",[t._v("把所有老数组元素按"),s("code",[t._v("key")]),t._v("或"),s("code",[t._v("index")]),t._v("放"),s("code",[t._v("Map")]),t._v("里，然后遍历新数组，插入老数组的元素，这是移动的情况。")])]),t._v(" "),s("h2",{attrs:{id:"每日一题"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#每日一题"}},[t._v("#")]),t._v(" 每日一题")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("https://github.com/WindrunnerMax/EveryDay\n")])])]),s("h2",{attrs:{id:"参考"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#参考"}},[t._v("#")]),t._v(" 参考")]),t._v(" "),s("div",{staticClass:"language- extra-class"},[s("pre",{pre:!0,attrs:{class:"language-text"}},[s("code",[t._v("https://zhuanlan.zhihu.com/p/89363990\nhttps://zhuanlan.zhihu.com/p/137251397\nhttps://github.com/sisterAn/blog/issues/22\nhttps://github.com/hujiulong/blog/issues/6\nhttps://juejin.cn/post/6844904165026562056\nhttps://www.cnblogs.com/forcheng/p/13246874.html\nhttps://zh-hans.reactjs.org/docs/reconciliation.html\nhttps://zxc0328.github.io/2017/09/28/react-16-source/\nhttps://blog.csdn.net/halations/article/details/109284050\nhttps://blog.csdn.net/susuzhe123/article/details/107890118\nhttps://github.com/Advanced-Frontend/Daily-Interview-Question/issues/47\nhttps://github.com/jianjiachenghub/react-deeplearn/blob/master/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/React16%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%906-Fiber%E9%93%BE%E5%BC%8Fdiff%E7%AE%97%E6%B3%95.md\n")])])])])}),[],!1,null,null,null);s.default=e.exports}}]);